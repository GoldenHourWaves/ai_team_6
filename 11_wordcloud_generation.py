"""
Task 11: ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
ê°ì„± ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ê¸ì •/ë¶€ì • ëŒ“ê¸€ ë¶„ë¦¬ í›„ ì›Œë“œí´ë¼ìš°ë“œ ì‹œê°í™”
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from wordcloud import WordCloud
from collections import Counter
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

# ë°ì´í„° ê²½ë¡œ
COMMUNITY_DIR = Path("data/Community_data")
OUTPUT_DIR = Path("output/visualizations")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# ê°ì„± ë§¤í•‘
SENTIMENT_MAP = {
    'Positive': 1.0,
    'Hopeful': 0.7,
    'Optimistic': 0.8,
    'Neutral': 0.0,
    'Skeptical': -0.3,
    'Skeptic': -0.3,
    'Fear': -0.8,
    'Panic': -0.9,
    'Negative': -1.0,
    'Bearish': -0.6,
    'Bullish': 0.6,
    'Worried': -0.5,
    'Anxious': -0.7,
    'Excited': 0.8,
    'FOMO': 0.5,
    'FUD': -0.7,
    'Anger': -0.8,
    'Analytical': 0.0
}

def load_community_data():
    """ì»¤ë®¤ë‹ˆí‹° ë°ì´í„° ë¡œë“œ"""
    
    print("\n" + "=" * 80)
    print("ğŸ“‚ ì»¤ë®¤ë‹ˆí‹° ë°ì´í„° ë¡œë“œ")
    print("=" * 80)
    
    file_path = COMMUNITY_DIR / "FINAL_10K_RECORDS.csv"
    df = pd.read_csv(file_path)
    
    # ê°ì„± ì ìˆ˜ ë³€í™˜
    df['sentiment_score'] = df['sentiment'].map(SENTIMENT_MAP)
    df['sentiment_score'].fillna(0, inplace=True)
    
    print(f"\nâœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {df.shape}")
    print(f"   í‰ê·  ê°ì„± ì ìˆ˜: {df['sentiment_score'].mean():.3f}")
    
    return df

def extract_keywords_by_sentiment(df):
    """ê°ì„±ë³„ë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    
    print("\n" + "=" * 80)
    print("ğŸ” ê°ì„±ë³„ í‚¤ì›Œë“œ ì¶”ì¶œ")
    print("=" * 80)
    
    # ê¸ì • ëŒ“ê¸€ (sentiment_score > 0.3)
    positive_df = df[df['sentiment_score'] > 0.3]
    
    # ë¶€ì • ëŒ“ê¸€ (sentiment_score < -0.3)
    negative_df = df[df['sentiment_score'] < -0.3]
    
    # ì¤‘ë¦½ ëŒ“ê¸€
    neutral_df = df[(df['sentiment_score'] >= -0.3) & (df['sentiment_score'] <= 0.3)]
    
    print(f"\nğŸ“Š ê°ì„± ë¶„í¬:")
    print(f"   ê¸ì • ëŒ“ê¸€: {len(positive_df)}ê°œ ({len(positive_df)/len(df)*100:.1f}%)")
    print(f"   ë¶€ì • ëŒ“ê¸€: {len(negative_df)}ê°œ ({len(negative_df)/len(df)*100:.1f}%)")
    print(f"   ì¤‘ë¦½ ëŒ“ê¸€: {len(neutral_df)}ê°œ ({len(neutral_df)/len(df)*100:.1f}%)")
    
    # í‚¤ì›Œë“œ ì¶”ì¶œ
    def extract_keywords(data_df):
        keywords = []
        for idx, row in data_df.iterrows():
            if pd.notna(row['keywords']):
                kw_list = [k.strip() for k in str(row['keywords']).split(',')]
                keywords.extend(kw_list)
        return keywords
    
    positive_keywords = extract_keywords(positive_df)
    negative_keywords = extract_keywords(negative_df)
    neutral_keywords = extract_keywords(neutral_df)
    
    print(f"\nğŸ“Š ì¶”ì¶œëœ í‚¤ì›Œë“œ ìˆ˜:")
    print(f"   ê¸ì •: {len(positive_keywords)}ê°œ")
    print(f"   ë¶€ì •: {len(negative_keywords)}ê°œ")
    print(f"   ì¤‘ë¦½: {len(neutral_keywords)}ê°œ")
    
    return positive_keywords, negative_keywords, neutral_keywords

def analyze_keyword_frequency(keywords, sentiment_type):
    """í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„"""
    
    print(f"\nğŸ“Š {sentiment_type} í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„:")
    print("-" * 80)
    
    keyword_counts = Counter(keywords)
    top_20 = keyword_counts.most_common(20)
    
    for i, (keyword, count) in enumerate(top_20, 1):
        print(f"   {i:2d}. {keyword:30s} : {count:4d}íšŒ")
    
    return keyword_counts

def create_wordcloud(keywords, title, output_filename, colormap='viridis'):
    """ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±"""
    
    print(f"\nğŸ“ˆ '{title}' ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì¤‘...")
    
    if len(keywords) == 0:
        print(f"âš ï¸  í‚¤ì›Œë“œê°€ ì—†ì–´ ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # í‚¤ì›Œë“œë¥¼ í…ìŠ¤íŠ¸ë¡œ ê²°í•©
    text = ' '.join(keywords)
    
    # ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
    wordcloud = WordCloud(
        width=1200,
        height=800,
        background_color='white',
        colormap=colormap,
        max_words=100,
        relative_scaling=0.5,
        min_font_size=10,
        collocations=False  # ë‹¨ì–´ ì¡°í•© ë°©ì§€
    ).generate(text)
    
    # ì‹œê°í™”
    fig, ax = plt.subplots(figsize=(15, 10))
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis('off')
    ax.set_title(title, fontsize=20, fontweight='bold', pad=20)
    
    plt.tight_layout(pad=0)
    
    output_file = OUTPUT_DIR / output_filename
    plt.savefig(output_file, dpi=300, bbox_inches='tight', facecolor='white')
    print(f"âœ… ì›Œë“œí´ë¼ìš°ë“œ ì €ì¥: {output_file}")
    
    plt.show()
    
    return wordcloud

def create_combined_wordcloud(positive_kw, negative_kw, neutral_kw):
    """ì „ì²´/ê¸ì •/ë¶€ì • 3ê°œ ì›Œë“œí´ë¼ìš°ë“œë¥¼ í•œ í™”ë©´ì—"""
    
    print("\n" + "=" * 80)
    print("ğŸ“ˆ í†µí•© ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±")
    print("=" * 80)
    
    fig, axes = plt.subplots(2, 2, figsize=(18, 14))
    fig.suptitle('ì»¤ë®¤ë‹ˆí‹° ê°ì„±ë³„ ì›Œë“œí´ë¼ìš°ë“œ', fontsize=20, fontweight='bold', y=0.98)
    
    # ===== ì „ì²´ í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ =====
    ax1 = axes[0, 0]
    all_keywords = positive_kw + negative_kw + neutral_kw
    if len(all_keywords) > 0:
        text = ' '.join(all_keywords)
        wc = WordCloud(width=800, height=600, background_color='white', 
                      colormap='viridis', max_words=80, 
                      collocations=False).generate(text)
        ax1.imshow(wc, interpolation='bilinear')
    ax1.axis('off')
    ax1.set_title('ì „ì²´ í‚¤ì›Œë“œ', fontsize=16, fontweight='bold', pad=10)
    
    # ===== ê¸ì • í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ =====
    ax2 = axes[0, 1]
    if len(positive_kw) > 0:
        text = ' '.join(positive_kw)
        wc = WordCloud(width=800, height=600, background_color='white', 
                      colormap='Greens', max_words=80,
                      collocations=False).generate(text)
        ax2.imshow(wc, interpolation='bilinear')
    else:
        ax2.text(0.5, 0.5, 'ê¸ì • í‚¤ì›Œë“œ ì—†ìŒ', ha='center', va='center',
                fontsize=16, transform=ax2.transAxes)
    ax2.axis('off')
    ax2.set_title(f'ê¸ì • í‚¤ì›Œë“œ ({len(positive_kw):,}ê°œ)', 
                 fontsize=16, fontweight='bold', pad=10, color='green')
    
    # ===== ë¶€ì • í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ =====
    ax3 = axes[1, 0]
    if len(negative_kw) > 0:
        text = ' '.join(negative_kw)
        wc = WordCloud(width=800, height=600, background_color='white', 
                      colormap='Reds', max_words=80,
                      collocations=False).generate(text)
        ax3.imshow(wc, interpolation='bilinear')
    else:
        ax3.text(0.5, 0.5, 'ë¶€ì • í‚¤ì›Œë“œ ì—†ìŒ', ha='center', va='center',
                fontsize=16, transform=ax3.transAxes)
    ax3.axis('off')
    ax3.set_title(f'ë¶€ì • í‚¤ì›Œë“œ ({len(negative_kw):,}ê°œ)', 
                 fontsize=16, fontweight='bold', pad=10, color='red')
    
    # ===== ì¤‘ë¦½ í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ =====
    ax4 = axes[1, 1]
    if len(neutral_kw) > 0:
        text = ' '.join(neutral_kw)
        wc = WordCloud(width=800, height=600, background_color='white', 
                      colormap='Blues', max_words=80,
                      collocations=False).generate(text)
        ax4.imshow(wc, interpolation='bilinear')
    else:
        ax4.text(0.5, 0.5, 'ì¤‘ë¦½ í‚¤ì›Œë“œ ì—†ìŒ', ha='center', va='center',
                fontsize=16, transform=ax4.transAxes)
    ax4.axis('off')
    ax4.set_title(f'ì¤‘ë¦½ í‚¤ì›Œë“œ ({len(neutral_kw):,}ê°œ)', 
                 fontsize=16, fontweight='bold', pad=10, color='blue')
    
    plt.tight_layout()
    
    output_file = OUTPUT_DIR / "15_wordcloud_combined.png"
    plt.savefig(output_file, dpi=300, bbox_inches='tight', facecolor='white')
    print(f"\nâœ… í†µí•© ì›Œë“œí´ë¼ìš°ë“œ ì €ì¥: {output_file}")
    
    plt.show()

def analyze_sentiment_keywords(df):
    """ê°ì„±ë³„ ëŒ€í‘œ í‚¤ì›Œë“œ ë¶„ì„"""
    
    print("\n" + "=" * 80)
    print("ğŸ” ê°ì„±ë³„ ëŒ€í‘œ í‚¤ì›Œë“œ ë¶„ì„")
    print("=" * 80)
    
    # í‚¤ì›Œë“œë³„ í‰ê·  ê°ì„± ì ìˆ˜ ê³„ì‚°
    keyword_sentiment = []
    
    for idx, row in df.iterrows():
        if pd.notna(row['keywords']):
            keywords = [k.strip() for k in str(row['keywords']).split(',')]
            for keyword in keywords:
                keyword_sentiment.append({
                    'keyword': keyword,
                    'sentiment_score': row['sentiment_score']
                })
    
    keyword_df = pd.DataFrame(keyword_sentiment)
    
    # í‚¤ì›Œë“œë³„ í‰ê·  ê°ì„± ë° ë¹ˆë„
    keyword_summary = keyword_df.groupby('keyword').agg({
        'sentiment_score': ['mean', 'count']
    }).reset_index()
    
    keyword_summary.columns = ['keyword', 'avg_sentiment', 'count']
    keyword_summary = keyword_summary[keyword_summary['count'] >= 5]  # ìµœì†Œ 5íšŒ ì´ìƒ
    
    # ê°€ì¥ ê¸ì •ì  í‚¤ì›Œë“œ
    most_positive = keyword_summary.nlargest(10, 'avg_sentiment')
    print(f"\nğŸŸ¢ ê°€ì¥ ê¸ì •ì  í‚¤ì›Œë“œ (Top 10):")
    for idx, row in most_positive.iterrows():
        print(f"   {row['keyword']:30s} | ê°ì„±: {row['avg_sentiment']:+.3f} | {row['count']:3.0f}íšŒ")
    
    # ê°€ì¥ ë¶€ì •ì  í‚¤ì›Œë“œ
    most_negative = keyword_summary.nsmallest(10, 'avg_sentiment')
    print(f"\nğŸ”´ ê°€ì¥ ë¶€ì •ì  í‚¤ì›Œë“œ (Top 10):")
    for idx, row in most_negative.iterrows():
        print(f"   {row['keyword']:30s} | ê°ì„±: {row['avg_sentiment']:+.3f} | {row['count']:3.0f}íšŒ")
    
    # íŠ¹ì • í‚¤ì›Œë“œ í™•ì¸
    target_keywords = ['buying the dip', 'panic selling', 'crash', 'dump', 
                      'liquidation', 'whale', 'manipulation']
    
    print(f"\nğŸ¯ ì£¼ìš” í‚¤ì›Œë“œ ê°ì„± ì ìˆ˜:")
    for keyword in target_keywords:
        matches = keyword_summary[keyword_summary['keyword'].str.lower() == keyword.lower()]
        if len(matches) > 0:
            row = matches.iloc[0]
            emoji = "ğŸ˜Š" if row['avg_sentiment'] > 0.2 else "ğŸ˜Ÿ" if row['avg_sentiment'] < -0.2 else "ğŸ˜"
            print(f"   {emoji} {keyword:30s} | ê°ì„±: {row['avg_sentiment']:+.3f} | {row['count']:3.0f}íšŒ")
        else:
            print(f"   âŒ {keyword:30s} | ë°ì´í„° ì—†ìŒ")

def create_keyword_frequency_chart(positive_counts, negative_counts):
    """í‚¤ì›Œë“œ ë¹ˆë„ ë¹„êµ ì°¨íŠ¸"""
    
    print("\n" + "=" * 80)
    print("ğŸ“Š í‚¤ì›Œë“œ ë¹ˆë„ ë¹„êµ ì°¨íŠ¸ ìƒì„±")
    print("=" * 80)
    
    fig, axes = plt.subplots(1, 2, figsize=(16, 8))
    fig.suptitle('ê°ì„±ë³„ Top 15 í‚¤ì›Œë“œ ë¹ˆë„', fontsize=18, fontweight='bold')
    
    # ===== ê¸ì • í‚¤ì›Œë“œ Top 15 =====
    ax1 = axes[0]
    if len(positive_counts) > 0:
        top_positive = positive_counts.most_common(15)
        keywords = [k for k, v in top_positive]
        counts = [v for k, v in top_positive]
        
        y_pos = np.arange(len(keywords))
        ax1.barh(y_pos, counts, color='green', alpha=0.7, edgecolor='black')
        ax1.set_yticks(y_pos)
        ax1.set_yticklabels(keywords, fontsize=10)
        ax1.invert_yaxis()
        ax1.set_xlabel('ë¹ˆë„', fontsize=12, fontweight='bold')
        ax1.set_title('ê¸ì • í‚¤ì›Œë“œ Top 15', fontsize=14, fontweight='bold', 
                     pad=10, color='green')
        ax1.grid(True, alpha=0.3, linestyle='--', axis='x')
        
        # ê°’ í‘œì‹œ
        for i, v in enumerate(counts):
            ax1.text(v + max(counts)*0.01, i, str(v), va='center', fontsize=9)
    
    # ===== ë¶€ì • í‚¤ì›Œë“œ Top 15 =====
    ax2 = axes[1]
    if len(negative_counts) > 0:
        top_negative = negative_counts.most_common(15)
        keywords = [k for k, v in top_negative]
        counts = [v for k, v in top_negative]
        
        y_pos = np.arange(len(keywords))
        ax2.barh(y_pos, counts, color='red', alpha=0.7, edgecolor='black')
        ax2.set_yticks(y_pos)
        ax2.set_yticklabels(keywords, fontsize=10)
        ax2.invert_yaxis()
        ax2.set_xlabel('ë¹ˆë„', fontsize=12, fontweight='bold')
        ax2.set_title('ë¶€ì • í‚¤ì›Œë“œ Top 15', fontsize=14, fontweight='bold', 
                     pad=10, color='red')
        ax2.grid(True, alpha=0.3, linestyle='--', axis='x')
        
        # ê°’ í‘œì‹œ
        for i, v in enumerate(counts):
            ax2.text(v + max(counts)*0.01, i, str(v), va='center', fontsize=9)
    
    plt.tight_layout()
    
    output_file = OUTPUT_DIR / "16_keyword_frequency_comparison.png"
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"\nâœ… í‚¤ì›Œë“œ ë¹ˆë„ ì°¨íŠ¸ ì €ì¥: {output_file}")
    
    plt.show()

def main():
    print("=" * 80)
    print("Task 11: ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±")
    print("=" * 80)
    
    # 1. ë°ì´í„° ë¡œë“œ
    df = load_community_data()
    
    # 2. ê°ì„±ë³„ í‚¤ì›Œë“œ ì¶”ì¶œ
    positive_kw, negative_kw, neutral_kw = extract_keywords_by_sentiment(df)
    
    # 3. í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„
    positive_counts = analyze_keyword_frequency(positive_kw, "ê¸ì •")
    negative_counts = analyze_keyword_frequency(negative_kw, "ë¶€ì •")
    neutral_counts = analyze_keyword_frequency(neutral_kw, "ì¤‘ë¦½")
    
    # 4. ê°œë³„ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
    if len(positive_kw) > 0:
        create_wordcloud(positive_kw, 'ê¸ì • í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ', 
                        'wordcloud_positive.png', colormap='Greens')
    
    if len(negative_kw) > 0:
        create_wordcloud(negative_kw, 'ë¶€ì • í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ', 
                        'wordcloud_negative.png', colormap='Reds')
    
    # 5. í†µí•© ì›Œë“œí´ë¼ìš°ë“œ
    create_combined_wordcloud(positive_kw, negative_kw, neutral_kw)
    
    # 6. ê°ì„±ë³„ ëŒ€í‘œ í‚¤ì›Œë“œ ë¶„ì„
    analyze_sentiment_keywords(df)
    
    # 7. í‚¤ì›Œë“œ ë¹ˆë„ ë¹„êµ ì°¨íŠ¸
    create_keyword_frequency_chart(positive_counts, negative_counts)
    
    # 8. ê²°ê³¼ ì €ì¥
    keyword_freq_df = pd.DataFrame([
        {'sentiment': 'positive', 'keyword': k, 'count': v} 
        for k, v in positive_counts.most_common(50)
    ] + [
        {'sentiment': 'negative', 'keyword': k, 'count': v} 
        for k, v in negative_counts.most_common(50)
    ])
    keyword_freq_df.to_csv(OUTPUT_DIR / "keyword_frequency_by_sentiment.csv", 
                           index=False, encoding='utf-8-sig')
    
    print("\n" + "=" * 80)
    print("Task 11 ì™„ë£Œ! âœ…")
    print("=" * 80)
    print(f"\nâœ… ìƒì„±ëœ íŒŒì¼:")
    print(f"   1. {OUTPUT_DIR / '15_wordcloud_combined.png'}")
    print(f"   2. {OUTPUT_DIR / '16_keyword_frequency_comparison.png'}")
    print(f"   3. {OUTPUT_DIR / 'wordcloud_positive.png'}")
    print(f"   4. {OUTPUT_DIR / 'wordcloud_negative.png'}")
    print(f"   5. {OUTPUT_DIR / 'keyword_frequency_by_sentiment.csv'}")

if __name__ == "__main__":
    main()
