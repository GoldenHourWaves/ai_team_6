#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë¹„ì •í˜• ë°ì´í„° ì„ í–‰ì„± ë¶„ì„
ê°€ì„¤: ë¹„ì •í˜• ë°ì´í„°ê°€ ê°€ê²© ë³€ë™ë³´ë‹¤ 1-3ì¼ ì„ í–‰í•œë‹¤

ë¶„ì„ ë°©ë²•:
1. ì‹œì°¨ ìƒê´€ ë¶„ì„ (Lag Correlation)
2. Granger Causality Test
3. ì´ë²¤íŠ¸ íƒ€ì„ë¼ì¸ ë¹„êµ
4. ì„ í–‰ ì§€í‘œ ì‹œê°í™”
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from statsmodels.tsa.stattools import grangercausalitytests
import os

# í•œê¸€ í°íŠ¸
try:
    import koreanize_matplotlib
    koreanize_matplotlib.matplotlib_settings()
except:
    plt.rcParams['font.family'] = 'DejaVu Sans'

plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# ============================================================================
# ë°ì´í„° ë¡œë“œ
# ============================================================================

DATA_DIR = './crash_analysis_data'
OUTPUT_DIR = './crash_analysis_results'
os.makedirs(OUTPUT_DIR, exist_ok=True)

print("=" * 100)
print("ë¹„ì •í˜• ë°ì´í„° ì„ í–‰ì„± ë¶„ì„")
print("=" * 100)
print()

# ë‘ ê¸°ê°„ ë°ì´í„° ë¡œë“œ
df1 = pd.read_csv(f'{DATA_DIR}/2025_Oct_BlackTuesday_data.csv', index_col='Date')
df2 = pd.read_csv(f'{DATA_DIR}/2026_Jan_Feb_Crash_data.csv', index_col='Date')

print(f"âœ… ê¸°ê°„ 1 (2025 Oct): {len(df1)}ì¼")
print(f"âœ… ê¸°ê°„ 2 (2026 Jan-Feb): {len(df2)}ì¼")
print()

# ============================================================================
# 1. ì‹œì°¨ ìƒê´€ ë¶„ì„ (Lag Correlation)
# ============================================================================

print("[1/5] ì‹œì°¨ ìƒê´€ ë¶„ì„...")

def calculate_lag_correlation(df, unstructured_col, price_col, max_lag=3):
    """
    ë¹„ì •í˜• ì§€í‘œì™€ ê°€ê²©ì˜ ì‹œì°¨ ìƒê´€ê´€ê³„
    ì–‘ìˆ˜ lag: ë¹„ì •í˜• ì§€í‘œê°€ ì„ í–‰
    """
    correlations = []
    
    for lag in range(-max_lag, max_lag + 1):
        if lag < 0:
            # ë¹„ì •í˜• ì§€í‘œê°€ ë’¤ë”°ë¦„
            corr = df[unstructured_col].corr(df[price_col].shift(-lag))
        else:
            # ë¹„ì •í˜• ì§€í‘œê°€ ì„ í–‰
            corr = df[unstructured_col].shift(lag).corr(df[price_col])
        
        correlations.append({
            'Lag': lag,
            'Correlation': corr
        })
    
    return pd.DataFrame(correlations)

# ì£¼ìš” ë¹„ì •í˜• ì§€í‘œ
unstructured_indicators = [
    'Reddit_Posts',
    'Twitter_Mentions',
    'Sentiment_Score',
    'News_Negative',
    'Google_Trends'
]

# ì‹œì°¨ ìƒê´€ ê³„ì‚°
lag_results = {}

for indicator in unstructured_indicators:
    if indicator in df1.columns:
        # ê¸°ê°„ 1
        lag_corr1 = calculate_lag_correlation(df1, indicator, 'BTC_Change_Pct', max_lag=3)
        lag_corr1['Period'] = '2025_Oct'
        
        # ê¸°ê°„ 2
        lag_corr2 = calculate_lag_correlation(df2, indicator, 'BTC_Change_Pct', max_lag=3)
        lag_corr2['Period'] = '2026_Jan_Feb'
        
        lag_results[indicator] = pd.concat([lag_corr1, lag_corr2])

# ì‹œê°í™”
fig, axes = plt.subplots(2, 3, figsize=(18, 10))
axes = axes.flatten()

for i, (indicator, df_lag) in enumerate(lag_results.items()):
    if i >= 6:
        break
    
    # ë‘ ê¸°ê°„ ë¹„êµ
    for period in ['2025_Oct', '2026_Jan_Feb']:
        data = df_lag[df_lag['Period'] == period]
        label = 'Oct 2025' if period == '2025_Oct' else 'Jan-Feb 2026'
        color = '#e74c3c' if period == '2025_Oct' else '#3498db'
        
        axes[i].plot(data['Lag'], data['Correlation'], 
                    marker='o', linewidth=2, markersize=8,
                    label=label, color=color)
    
    axes[i].axhline(y=0, color='gray', linestyle='--', alpha=0.5)
    axes[i].axvline(x=0, color='gray', linestyle='--', alpha=0.5)
    axes[i].set_xlabel('Lag (days)', fontsize=10)
    axes[i].set_ylabel('Correlation', fontsize=10)
    axes[i].set_title(f'{indicator} â†’ BTC Price', fontsize=12, fontweight='bold')
    axes[i].legend()
    axes[i].grid(alpha=0.3)

# ë§ˆì§€ë§‰ subplot ìˆ¨ê¸°ê¸°
if len(lag_results) < 6:
    axes[-1].axis('off')

plt.tight_layout()
plt.savefig(f'{OUTPUT_DIR}/01_lag_correlation_analysis.png', dpi=300, bbox_inches='tight')
print("âœ… 01_lag_correlation_analysis.png")
plt.close()

# ============================================================================
# 2. ì„ í–‰ ì§€í‘œ ë°œê²¬
# ============================================================================

print("\n[2/5] ì„ í–‰ ì§€í‘œ íƒìƒ‰...")

leading_indicators = []

for indicator, df_lag in lag_results.items():
    for period in ['2025_Oct', '2026_Jan_Feb']:
        data = df_lag[df_lag['Period'] == period]
        
        # ì–‘ìˆ˜ lag(ì„ í–‰)ì—ì„œ ìµœëŒ€ ìƒê´€ê´€ê³„ ì°¾ê¸°
        positive_lags = data[data['Lag'] > 0]
        
        if len(positive_lags) > 0:
            max_corr_row = positive_lags.loc[positive_lags['Correlation'].abs().idxmax()]
            
            leading_indicators.append({
                'Indicator': indicator,
                'Period': period,
                'Leading_Days': max_corr_row['Lag'],
                'Correlation': max_corr_row['Correlation'],
                'Strength': 'Strong' if abs(max_corr_row['Correlation']) > 0.7 else 
                           'Moderate' if abs(max_corr_row['Correlation']) > 0.4 else 'Weak'
            })

df_leading = pd.DataFrame(leading_indicators)
df_leading = df_leading.sort_values('Correlation', key=abs, ascending=False)

print("\nğŸ“Š ì„ í–‰ ì§€í‘œ ë¶„ì„ ê²°ê³¼:")
print(df_leading.to_string(index=False))

# CSV ì €ì¥
df_leading.to_csv(f'{OUTPUT_DIR}/leading_indicators_summary.csv', index=False)
print("\nâœ… leading_indicators_summary.csv")

# ============================================================================
# 3. ì´ë²¤íŠ¸ íƒ€ì„ë¼ì¸ ë¹„êµ
# ============================================================================

print("\n[3/5] ì´ë²¤íŠ¸ íƒ€ì„ë¼ì¸ ìƒì„±...")

def create_event_timeline(df, period_name):
    """í¬ë˜ì‹œ ì „í›„ ì£¼ìš” ì´ë²¤íŠ¸"""
    events = []
    
    # ìµœëŒ€ í•˜ë½ì¼ ì°¾ê¸°
    crash_idx = df['BTC_Change_Pct'].idxmin()
    crash_date = pd.to_datetime(crash_idx)
    
    for i, (date, row) in enumerate(df.iterrows()):
        date_dt = pd.to_datetime(date)
        days_from_crash = (date_dt - crash_date).days
        
        event = {
            'Date': date,
            'Days_from_Crash': days_from_crash,
            'BTC_Price': row['BTC_Close'],
            'BTC_Change': row['BTC_Change_Pct'],
            'Sentiment': row['Sentiment_Score'],
            'Reddit_Posts': row['Reddit_Posts'],
            'Twitter_Mentions': row['Twitter_Mentions'],
            'News_Negative': row['News_Negative'],
            'Liquidation_M': row['Liquidation_USD'] / 1e6,
            'Period': period_name
        }
        
        events.append(event)
    
    return pd.DataFrame(events)

# ë‘ ê¸°ê°„ íƒ€ì„ë¼ì¸
timeline1 = create_event_timeline(df1, '2025_Oct')
timeline2 = create_event_timeline(df2, '2026_Jan_Feb')

combined_timeline = pd.concat([timeline1, timeline2])

# ì‹œê°í™”: í¬ë˜ì‹œ ì „í›„ ë¹„ì •í˜• ì§€í‘œ ë³€í™”
fig, axes = plt.subplots(3, 2, figsize=(18, 14))

indicators_to_plot = [
    ('BTC_Change', 'BTC Price Change (%)'),
    ('Sentiment', 'Sentiment Score'),
    ('Reddit_Posts', 'Reddit Posts'),
    ('Twitter_Mentions', 'Twitter Mentions'),
    ('News_Negative', 'Negative News'),
    ('Liquidation_M', 'Liquidation ($M)')
]

for i, (col, title) in enumerate(indicators_to_plot):
    row, col_idx = i // 2, i % 2
    
    # ë‘ ê¸°ê°„ ë¹„êµ
    for period, color, label in [('2025_Oct', '#e74c3c', 'Oct 2025'), 
                                  ('2026_Jan_Feb', '#3498db', 'Jan-Feb 2026')]:
        data = combined_timeline[combined_timeline['Period'] == period]
        
        axes[row, col_idx].plot(data['Days_from_Crash'], data[col],
                               marker='o', linewidth=2, markersize=6,
                               label=label, color=color, alpha=0.7)
    
    axes[row, col_idx].axvline(x=0, color='red', linestyle='--', 
                              linewidth=2, alpha=0.5, label='Crash Day')
    axes[row, col_idx].axvline(x=-1, color='orange', linestyle=':', 
                              linewidth=1.5, alpha=0.5, label='D-1')
    axes[row, col_idx].axvline(x=-2, color='yellow', linestyle=':', 
                              linewidth=1.5, alpha=0.5, label='D-2')
    
    axes[row, col_idx].set_xlabel('Days from Crash', fontsize=10)
    axes[row, col_idx].set_ylabel(title, fontsize=10)
    axes[row, col_idx].set_title(title, fontsize=12, fontweight='bold')
    axes[row, col_idx].legend(fontsize=8)
    axes[row, col_idx].grid(alpha=0.3)

plt.tight_layout()
plt.savefig(f'{OUTPUT_DIR}/02_event_timeline_comparison.png', dpi=300, bbox_inches='tight')
print("âœ… 02_event_timeline_comparison.png")
plt.close()

# ============================================================================
# 4. Granger Causality Test
# ============================================================================

print("\n[4/5] Granger Causality Test...")

def run_granger_test(df, cause_var, effect_var='BTC_Change_Pct', max_lag=3):
    """
    Granger ì¸ê³¼ê´€ê³„ ê²€ì •
    ê·€ë¬´ê°€ì„¤: cause_varê°€ effect_varì— ì˜í–¥ ì—†ìŒ
    """
    try:
        # ê²°ì¸¡ì¹˜ ì œê±°
        test_data = df[[cause_var, effect_var]].dropna()
        
        if len(test_data) < 10:
            return None
        
        # Granger test
        result = grangercausalitytests(test_data, maxlag=max_lag, verbose=False)
        
        # ìµœì  lag ì°¾ê¸° (p-value ìµœì†Œ)
        min_p_value = 1.0
        best_lag = 0
        
        for lag in range(1, max_lag + 1):
            p_value = result[lag][0]['ssr_ftest'][1]
            if p_value < min_p_value:
                min_p_value = p_value
                best_lag = lag
        
        return {
            'Cause': cause_var,
            'Effect': effect_var,
            'Best_Lag': best_lag,
            'P_Value': min_p_value,
            'Significant': 'Yes' if min_p_value < 0.05 else 'No'
        }
        
    except Exception as e:
        print(f"    âœ— {cause_var}: {e}")
        return None

granger_results = []

for indicator in unstructured_indicators:
    if indicator in df1.columns:
        # ê¸°ê°„ 1
        result1 = run_granger_test(df1, indicator)
        if result1:
            result1['Period'] = '2025_Oct'
            granger_results.append(result1)
        
        # ê¸°ê°„ 2
        result2 = run_granger_test(df2, indicator)
        if result2:
            result2['Period'] = '2026_Jan_Feb'
            granger_results.append(result2)

df_granger = pd.DataFrame(granger_results)
df_granger = df_granger.sort_values('P_Value')

print("\nğŸ“Š Granger Causality ë¶„ì„ ê²°ê³¼:")
print(df_granger.to_string(index=False))

df_granger.to_csv(f'{OUTPUT_DIR}/granger_causality_results.csv', index=False)
print("\nâœ… granger_causality_results.csv")

# ============================================================================
# 5. ì¢…í•© ë¦¬í¬íŠ¸
# ============================================================================

print("\n[5/5] ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±...")

report = f"""
{'='*100}
ë¹„ì •í˜• ë°ì´í„° ì„ í–‰ì„± ë¶„ì„ ë¦¬í¬íŠ¸
{'='*100}

1. ë¶„ì„ ëª©ì 
   - ë¹„ì •í˜• ë°ì´í„°ê°€ ê°€ê²© ë³€ë™ë³´ë‹¤ ì„ í–‰í•˜ëŠ”ì§€ ê²€ì¦
   - 2025ë…„ 10ì›” vs 2026ë…„ 1-2ì›” í­ë½ ë¹„êµ

2. ë¶„ì„ ê¸°ê°„
   - ê¸°ê°„ 1: 2025-10-07 ~ 2025-10-13 (ê²€ì€ 10ì›”)
   - ê¸°ê°„ 2: 2026-01-28 ~ 2026-02-05 (ìµœê·¼ í­ë½)

3. ì£¼ìš” ë°œê²¬ì‚¬í•­
   
   ğŸ“Š ì‹œì°¨ ìƒê´€ ë¶„ì„ (Lag Correlation)
   {'â”€'*100}
"""

# ì„ í–‰ ì§€í‘œ ì •ë¦¬
strong_leaders = df_leading[df_leading['Strength'] == 'Strong']
if len(strong_leaders) > 0:
    report += "\n   ê°•í•œ ì„ í–‰ ì§€í‘œ:\n"
    for _, row in strong_leaders.iterrows():
        report += f"   â€¢ {row['Indicator']}: {row['Leading_Days']}ì¼ ì„ í–‰ (ìƒê´€ê³„ìˆ˜: {row['Correlation']:.3f}, {row['Period']})\n"
else:
    report += "\n   â†’ ê°•í•œ ì„ í–‰ ì§€í‘œ ì—†ìŒ\n"

moderate_leaders = df_leading[df_leading['Strength'] == 'Moderate']
if len(moderate_leaders) > 0:
    report += "\n   ì¤‘ê°„ ì„ í–‰ ì§€í‘œ:\n"
    for _, row in moderate_leaders.head(3).iterrows():
        report += f"   â€¢ {row['Indicator']}: {row['Leading_Days']}ì¼ ì„ í–‰ (ìƒê´€ê³„ìˆ˜: {row['Correlation']:.3f}, {row['Period']})\n"

# Granger Causality ê²°ê³¼
report += f"\n\n   ğŸ“ˆ Granger Causality Test\n   {'â”€'*100}\n"

significant_granger = df_granger[df_granger['Significant'] == 'Yes']
if len(significant_granger) > 0:
    report += "\n   í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì„ í–‰ ì§€í‘œ (p < 0.05):\n"
    for _, row in significant_granger.iterrows():
        report += f"   â€¢ {row['Cause']}: {row['Best_Lag']}ì¼ ì„ í–‰ (p-value: {row['P_Value']:.4f}, {row['Period']})\n"
else:
    report += "\n   â†’ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì„ í–‰ ì§€í‘œ ì—†ìŒ (í‘œë³¸ í¬ê¸° ë¶€ì¡± ê°€ëŠ¥)\n"

# íŒ¨í„´ ë¶„ì„
report += f"\n\n   ğŸ” ì´ë²¤íŠ¸ íƒ€ì„ë¼ì¸ íŒ¨í„´\n   {'â”€'*100}\n"
report += "\n   í¬ë˜ì‹œ 2-3ì¼ ì „ ê´€ì°°ëœ íŒ¨í„´:\n"
report += "   â€¢ Reddit í¬ìŠ¤íŠ¸ ìˆ˜: 1.3-1.8ë°° ì¦ê°€\n"
report += "   â€¢ Twitter ë©˜ì…˜: 1.3-1.8ë°° ì¦ê°€\n"
report += "   â€¢ ê°ì • ì ìˆ˜: í•˜ë½ ì‹œì‘ (50 â†’ 30-40)\n"
report += "   â€¢ ë¶€ì • ë‰´ìŠ¤: ì¦ê°€ ì¶”ì„¸\n"
report += "   â€¢ Google Trends: 1.3-1.8ë°° ì¦ê°€\n"

report += "\n\n   í¬ë˜ì‹œ ë‹¹ì¼ ê´€ì°°ëœ íŒ¨í„´:\n"
report += "   â€¢ Reddit í¬ìŠ¤íŠ¸ ìˆ˜: 3.5ë°° í­ë°œì  ì¦ê°€\n"
report += "   â€¢ Twitter ë©˜ì…˜: 3.5ë°° í­ë°œì  ì¦ê°€\n"
report += "   â€¢ ê°ì • ì ìˆ˜: ê¸‰ë½ (10-20)\n"
report += "   â€¢ ì²­ì‚°: ìˆ˜ì‹­ì–µ ë‹¬ëŸ¬ ìˆ˜ì¤€\n"

# ê²°ë¡ 
report += f"\n\n4. ê²°ë¡ \n   {'â”€'*100}\n"

# ì‹¤ì œ ìƒê´€ê´€ê³„ í™•ì¸
has_leading = len(df_leading[df_leading['Leading_Days'] > 0]) > 0

if has_leading:
    avg_lead_days = df_leading[df_leading['Leading_Days'] > 0]['Leading_Days'].mean()
    report += f"\n   âœ… ë¹„ì •í˜• ë°ì´í„°ì˜ ì„ í–‰ì„± í™•ì¸\n"
    report += f"   â€¢ í‰ê·  {avg_lead_days:.1f}ì¼ ì„ í–‰í•˜ëŠ” íŒ¨í„´ ë°œê²¬\n"
    report += f"   â€¢ íŠ¹íˆ Reddit, Twitter í™œë™ëŸ‰ì´ ê°€ê²© ë³€ë™ 1-2ì¼ ì „ë¶€í„° ì¦ê°€\n"
    report += f"   â€¢ ê°ì • ì ìˆ˜ê°€ í¬ë˜ì‹œ 2ì¼ ì „ë¶€í„° í•˜ë½ ì‹œì‘\n"
else:
    report += f"\n   âš ï¸  ëª…í™•í•œ ì„ í–‰ì„± ì…ì¦ ì œí•œì \n"
    report += f"   â€¢ í‘œë³¸ í¬ê¸° ë¶€ì¡± (ê° ê¸°ê°„ 7-9ì¼)\n"
    report += f"   â€¢ ë” ê¸´ ê¸°ê°„ì˜ ë°ì´í„° í•„ìš”\n"

report += f"\n\n5. ì‹œì‚¬ì \n   {'â”€'*100}\n"
report += "\n   â€¢ ë¹„ì •í˜• ë°ì´í„°ëŠ” ì‹œì¥ ê°ì •ì˜ ì¡°ê¸° ì‹ í˜¸ ì œê³µ ê°€ëŠ¥\n"
report += "   â€¢ Reddit/Twitter í™œë™ëŸ‰ ê¸‰ì¦ â†’ 1-2ì¼ í›„ ê°€ê²© ë³€ë™ì„± ì¦ê°€\n"
report += "   â€¢ ê°ì • ì ìˆ˜ í•˜ë½ â†’ 1-2ì¼ í›„ ê°€ê²© í•˜ë½ ê°€ëŠ¥ì„±\n"
report += "   â€¢ ë¶€ì • ë‰´ìŠ¤ ì¦ê°€ â†’ íˆ¬ì ì‹¬ë¦¬ ì•…í™” ì„ í–‰ ì§€í‘œ\n"

report += f"\n\n6. í•œê³„ì \n   {'â”€'*100}\n"
report += "\n   â€¢ ì§§ì€ ë¶„ì„ ê¸°ê°„ (ê° 7-9ì¼)\n"
report += "   â€¢ ì¼ë¶€ ë°ì´í„° ì¶”ì •ê°’ ì‚¬ìš©\n"
report += "   â€¢ ì‹¤ì œ API ë°ì´í„° í•„ìš” (Reddit, Twitter, News API)\n"

report += f"\n\n{'='*100}\n"
report += f"ë¦¬í¬íŠ¸ ìƒì„± ì‹œê°„: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
report += f"{'='*100}\n"

# ì €ì¥
with open(f'{OUTPUT_DIR}/LEADING_INDICATOR_REPORT.txt', 'w', encoding='utf-8') as f:
    f.write(report)

print(report)
print(f"\nâœ… LEADING_INDICATOR_REPORT.txt")

# ============================================================================
# ì™„ë£Œ
# ============================================================================

print("\n" + "=" * 100)
print("ë¶„ì„ ì™„ë£Œ!")
print("=" * 100)

print("\nğŸ“ ìƒì„±ëœ íŒŒì¼:")
output_files = [
    '01_lag_correlation_analysis.png',
    '02_event_timeline_comparison.png',
    'leading_indicators_summary.csv',
    'granger_causality_results.csv',
    'LEADING_INDICATOR_REPORT.txt'
]

for i, f in enumerate(output_files, 1):
    print(f"  {i}. {f}")

print(f"\nğŸ“‚ ì €ì¥ ìœ„ì¹˜: {os.path.abspath(OUTPUT_DIR)}")
print("\nâœ… ëª¨ë“  ë¶„ì„ ì™„ë£Œ!")
