"""
Task 3: ì „ì²´ ë°ì´í„° í†µí•© (Master DataFrame ìƒì„±)
ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ëª¨ë“  ì •ì œëœ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ DataFrameìœ¼ë¡œ ë³‘í•©
"""

import pandas as pd
import numpy as np
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# ì •ì œëœ ë°ì´í„° ê²½ë¡œ
CLEANED_DIR = Path("data/processed/cleaned")
OUTPUT_DIR = Path("data/processed/integrated")
OUTPUT_DIR.mkdir(exist_ok=True)

def aggregate_sns_daily(df_sns):
    """SNS/YouTube ë°ì´í„°ë¥¼ ì¼ë³„ë¡œ ì§‘ê³„"""
    print("  ğŸ“Š SNS/YouTube ë°ì´í„° ì¼ë³„ ì§‘ê³„ ì¤‘...")
    
    # ì¼ë³„ ì§‘ê³„
    daily_agg = df_sns.groupby('date').agg({
        'engagement': ['sum', 'mean', 'max'],
        'content': 'count',
        'platform': lambda x: (x == 'YouTube').sum(),  # YouTube ê²Œì‹œë¬¼ ìˆ˜
        'type': lambda x: (x == 'video').sum()  # ë¹„ë””ì˜¤ ìˆ˜
    }).reset_index()
    
    # ì»¬ëŸ¼ëª… í‰íƒ„í™”
    daily_agg.columns = [
        'date',
        'sns_engagement_total',
        'sns_engagement_mean',
        'sns_engagement_max',
        'sns_post_count',
        'sns_youtube_count',
        'sns_video_count'
    ]
    
    print(f"  âœ… SNS ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: {len(daily_agg)}ì¼")
    return daily_agg

def integrate_all_data():
    """ëª¨ë“  ì •ì œëœ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ Master DataFrameìœ¼ë¡œ í†µí•©"""
    
    print("=" * 80)
    print("Task 3: ì „ì²´ ë°ì´í„° í†µí•© ì‹œì‘")
    print("=" * 80)
    
    # ===== 1. Features Daily ë¡œë“œ (ë‰´ìŠ¤ í…Œë§ˆ ë°ì´í„°) =====
    print("\n[1/4] Features Daily ë°ì´í„° ë¡œë“œ ì¤‘...")
    df_features = pd.read_csv(CLEANED_DIR / "features_daily_cleaned.csv")
    df_features['date'] = pd.to_datetime(df_features['date'])
    print(f"  Shape: {df_features.shape}")
    print(f"  ë‚ ì§œ ë²”ìœ„: {df_features['date'].min()} ~ {df_features['date'].max()}")
    
    # ===== 2. Daily Data ë¡œë“œ (ê°€ê²© + ê±°ì‹œê²½ì œ ì§€í‘œ) =====
    print("\n[2/4] Daily Data ë¡œë“œ ì¤‘...")
    df_daily = pd.read_csv(CLEANED_DIR / "daily_data_cleaned.csv")
    df_daily['date'] = pd.to_datetime(df_daily['date'])
    print(f"  Shape: {df_daily.shape}")
    print(f"  ë‚ ì§œ ë²”ìœ„: {df_daily['date'].min()} ~ {df_daily['date'].max()}")
    
    # ===== 3. M2 & Inflation ë¡œë“œ =====
    print("\n[3/4] M2 & Inflation ë°ì´í„° ë¡œë“œ ì¤‘...")
    df_m2 = pd.read_csv(CLEANED_DIR / "m2_inflation_daily_expanded.csv")
    df_m2['date'] = pd.to_datetime(df_m2['date'])
    print(f"  Shape: {df_m2.shape}")
    print(f"  ë‚ ì§œ ë²”ìœ„: {df_m2['date'].min()} ~ {df_m2['date'].max()}")
    
    # ===== 4. SNS/YouTube ë¡œë“œ ë° ì§‘ê³„ =====
    print("\n[4/4] SNS/YouTube ë°ì´í„° ë¡œë“œ ë° ì§‘ê³„ ì¤‘...")
    df_sns = pd.read_csv(CLEANED_DIR / "sns_youtube_cleaned.csv")
    df_sns['date'] = pd.to_datetime(df_sns['date'])
    print(f"  ì›ë³¸ Shape: {df_sns.shape}")
    print(f"  ë‚ ì§œ ë²”ìœ„: {df_sns['date'].min()} ~ {df_sns['date'].max()}")
    
    df_sns_daily = aggregate_sns_daily(df_sns)
    
    # ===== ë°ì´í„° ë³‘í•© =====
    print("\n" + "=" * 80)
    print("ğŸ“¦ ë°ì´í„° ë³‘í•© ì‹œì‘")
    print("=" * 80)
    
    # Step 1: Features + Daily Data
    print("\n[Step 1] Features + Daily Data ë³‘í•©...")
    df_master = df_features.merge(df_daily, on='date', how='outer')
    print(f"  ë³‘í•© í›„ Shape: {df_master.shape}")
    print(f"  ê²°ì¸¡ì¹˜: {df_master.isna().sum().sum()}ê°œ")
    
    # Step 2: + M2 & Inflation
    print("\n[Step 2] + M2 & Inflation ë³‘í•©...")
    df_master = df_master.merge(df_m2, on='date', how='left')
    print(f"  ë³‘í•© í›„ Shape: {df_master.shape}")
    print(f"  ê²°ì¸¡ì¹˜: {df_master.isna().sum().sum()}ê°œ")
    
    # Step 3: + SNS Daily
    print("\n[Step 3] + SNS Daily ë³‘í•©...")
    df_master = df_master.merge(df_sns_daily, on='date', how='left')
    print(f"  ë³‘í•© í›„ Shape: {df_master.shape}")
    print(f"  ê²°ì¸¡ì¹˜: {df_master.isna().sum().sum()}ê°œ")
    
    # ===== ë‚ ì§œ ìˆœ ì •ë ¬ =====
    df_master = df_master.sort_values('date').reset_index(drop=True)
    
    # ===== SNS ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ë°ì´í„°ê°€ ì—†ëŠ” ë‚ ì€ 0ìœ¼ë¡œ) =====
    sns_cols = [col for col in df_master.columns if col.startswith('sns_')]
    for col in sns_cols:
        df_master[col] = df_master[col].fillna(0)
    
    print("\n" + "=" * 80)
    print("ğŸ“Š í†µí•© ë°ì´í„° ì •ë³´")
    print("=" * 80)
    
    print(f"\nâœ… Master DataFrame ìƒì„± ì™„ë£Œ!")
    print(f"   Shape: {df_master.shape}")
    print(f"   ë‚ ì§œ ë²”ìœ„: {df_master['date'].min()} ~ {df_master['date'].max()}")
    print(f"   ì´ ê²°ì¸¡ì¹˜: {df_master.isna().sum().sum()}ê°œ")
    
    # ì»¬ëŸ¼ ê·¸ë£¹ë³„ ì •ë³´
    print(f"\nğŸ“‹ ì»¬ëŸ¼ ê·¸ë£¹:")
    print(f"   - ë‚ ì§œ: 1ê°œ")
    print(f"   - ë‰´ìŠ¤ ë©”íƒ€: {len([c for c in df_master.columns if c.startswith('n_') or c.startswith('tone_')])}ê°œ")
    print(f"   - ë‰´ìŠ¤ í…Œë§ˆ: {len([c for c in df_master.columns if c.startswith('theme_cnt_')])}ê°œ")
    print(f"   - ê°€ê²© ë°ì´í„°: {len([c for c in df_master.columns if 'Price' in c or 'Open_Interest' in c])}ê°œ")
    print(f"   - ê±°ì‹œê²½ì œ: {len([c for c in df_master.columns if any(x in c for x in ['Yield', 'USD', 'M2', 'CPI'])])}ê°œ")
    print(f"   - SNS: {len(sns_cols)}ê°œ")
    
    # ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ì»¬ëŸ¼ í™•ì¸
    missing_cols = df_master.columns[df_master.isna().any()].tolist()
    if missing_cols:
        print(f"\nâš ï¸  ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ì»¬ëŸ¼ ({len(missing_cols)}ê°œ):")
        for col in missing_cols[:10]:  # ìƒìœ„ 10ê°œë§Œ í‘œì‹œ
            missing_count = df_master[col].isna().sum()
            missing_pct = (missing_count / len(df_master)) * 100
            print(f"   - {col}: {missing_count}ê°œ ({missing_pct:.2f}%)")
        if len(missing_cols) > 10:
            print(f"   ... ì™¸ {len(missing_cols) - 10}ê°œ")
    
    # ===== ë°ì´í„° ì €ì¥ =====
    print("\n" + "=" * 80)
    print("ğŸ’¾ ë°ì´í„° ì €ì¥ ì¤‘...")
    print("=" * 80)
    
    # CSV ì €ì¥
    output_csv = OUTPUT_DIR / "master_data_integrated.csv"
    df_master.to_csv(output_csv, index=False)
    print(f"  âœ… {output_csv}")
    
    # ìš”ì•½ í†µê³„ ì €ì¥
    summary_file = OUTPUT_DIR / "master_data_summary.txt"
    with open(summary_file, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("Master DataFrame ìš”ì•½ í†µê³„\n")
        f.write("=" * 80 + "\n\n")
        f.write(f"Shape: {df_master.shape}\n")
        f.write(f"ë‚ ì§œ ë²”ìœ„: {df_master['date'].min()} ~ {df_master['date'].max()}\n")
        f.write(f"ì´ ê²°ì¸¡ì¹˜: {df_master.isna().sum().sum()}ê°œ\n\n")
        
        f.write("=" * 80 + "\n")
        f.write("ì»¬ëŸ¼ ëª©ë¡\n")
        f.write("=" * 80 + "\n\n")
        for i, col in enumerate(df_master.columns, 1):
            dtype = df_master[col].dtype
            null_count = df_master[col].isna().sum()
            null_pct = (null_count / len(df_master)) * 100
            f.write(f"{i:3d}. {col:50s} | {str(dtype):20s} | ê²°ì¸¡: {null_count:3d} ({null_pct:5.2f}%)\n")
        
        f.write("\n" + "=" * 80 + "\n")
        f.write("ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ê¸°ë³¸ í†µê³„\n")
        f.write("=" * 80 + "\n\n")
        f.write(df_master.describe().to_string())
    
    print(f"  âœ… {summary_file}")
    
    # ìƒ˜í”Œ ë°ì´í„° í™•ì¸
    print("\n" + "=" * 80)
    print("ğŸ” ë°ì´í„° ìƒ˜í”Œ (ì²˜ìŒ 5í–‰)")
    print("=" * 80)
    
    # ì£¼ìš” ì»¬ëŸ¼ë§Œ ì„ íƒí•´ì„œ ì¶œë ¥
    key_cols = ['date', 'BTC_Price', 'tone_mean', 'Open_Interest', 
                'M2SL', 'CPI_YoY_Inflation_Rate', 'sns_post_count']
    available_cols = [col for col in key_cols if col in df_master.columns]
    print(df_master[available_cols].head().to_string(index=False))
    
    print("\n" + "=" * 80)
    print("Task 3 ì™„ë£Œ! âœ…")
    print("=" * 80)
    print(f"\nâœ… í†µí•© ë°ì´í„°ê°€ {output_csv}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    return df_master

if __name__ == "__main__":
    master_df = integrate_all_data()
    
    print(f"\nâœ… Master DataFrameì´ ë©”ëª¨ë¦¬ì— ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"   ë³€ìˆ˜ëª…: master_df")
    print(f"   Shape: {master_df.shape}")
